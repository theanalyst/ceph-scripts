#!/usr/bin/python
#
# ceph-gentle-drain
# Author: Dan van der Ster <daniel.vanderster@cern.ch>
#
# Slowly drain a list of OSDs or an entire host causing minimal impact in a ceph cluster.
#

import sys
import getopt
import commands
import json
import time
import subprocess


def pool_exists(pool):
    cmd = ["ceph", "osd", "pool", "stats", pool]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    return True if proc.returncode == 0 else False


def create_pool(pool):
    cmd = ["ceph", "osd", "pool", "create", pool, "100", "100"]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    if proc.returncode != 0:
        raise Exception(stderr)


def delete_pool(pool):
    """
    Delete a pool is dangerous, so the operation is disable by Ceph in default.
    In that case, this function is expected to fail, you need to delete the
    pool manually if you really mean it:

    $ ceph osd pool delete <pool> <pool> --yes-i-really-really-mean-it
    """
    cmd = ["ceph", "osd", "pool", "delete", pool]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    if proc.returncode != 0:
        raise Exception(stderr)


def prepare(bench_pool):
    print("prepare draining")

    if pool_exists(bench_pool):
        print("pool %s already exists" % bench_pool)
        return

    print("create benchmark pool %s to measure latency" % bench_pool)
    create_pool(bench_pool)


def cleanup(bench_pool):
    print("cleaning up")

    if pool_exists(bench_pool):
        # delete a pool is disabled by Ceph in default
        try:
            delete_pool(bench_pool)
        except Exception as e:
            print("delete pool %s failed: %s" % (bench_pool, e))
            print("You need to manually detele the pool %s" % bench_pool)

    print("cleanup done")


def update_osd_tree():
    global osd_tree
    print "update_osd_tree: loading ceph osd tree"
    osd_tree_json = commands.getoutput(
        'ceph osd tree --format=json 2>/dev/null')
    osd_tree = json.loads(osd_tree_json)
    print "update_osd_tree: done"


def get_children(host):
    global osd_tree
    osds = []

    print ("get_children: loading children for %s" % (host))
    for node in osd_tree['nodes']:
        if node['name'] == host:
            osds = list("osd.%s" % (i) for i in node['children'])
    print ("get_children: done")
    return osds


def check_device_class(host, osds):
    global osd_tree
    classes = set()

    print ("check_device_class: Checking %s has only one device class" % (host))
    for node in osd_tree['nodes']:
        if node['name'] in osds:
            classes.add(node['device_class'])
    if len(classes) > 1:
        print ("check_device_class: Multiple classes detected on %s: %s" % (host, ','.join(sorted(classes))))
        print ("check_device_class: Reweighting a subtree with different classes is typically wrong.")
        sys.exit(0)
    print ("check_device_class: done")


def get_crush_weight(osd):
    global osd_tree
    for node in osd_tree['nodes']:
        if node['name'] == osd:
            weight = float(node['crush_weight'])
            print "get_crush_weight: %s has weight %s" % (osd, weight)
            return weight
    raise Exception('Undefined crush_weight for %s' % osd)


def measure_latency(pool):
    print "measure_latency: measuring 4kB write latency"
    latency = commands.getoutput(
        "rados -p %s bench 10 write -t 1 -b 4096 2>/dev/null | egrep -i 'average latency' | awk '{print $3}'" %
     pool)
    latency_ms = 1000*float(latency)
    print "measure_latency: current latency is %s ms" % latency_ms
    return latency_ms


def get_num_backfilling():
    #cmd = "ceph health detail | grep pg | grep -v stuck | grep backfilling | wc -l"
    cmd = "ceph pg ls backfilling | wc -l"
    out = commands.getoutput(cmd)
    n = int(out)
    print "get_num_backfilling: PGs currently backfilling: %s" % n
    return n


def crush_reweight(osd, weight):
    cmd = "ceph osd crush reweight %s %s" % (osd, weight)
    print "crush_reweight: calling %s" % cmd
    out = commands.getoutput(cmd)
    print "crush_reweight: %s" % out


def crush_reweight_subtree(host, weight):
    cmd = "ceph osd crush reweight-subtree %s %s" % (host, weight)
    print "crush_reweight_subtree: calling %s" % cmd
    out = commands.getoutput(cmd)
    print "crush_reweight: %s" % out


def all_done(bench_pool):
    print "All done"
    cleanup(bench_pool)
    sys.exit(0)


def drain(osds, host, max_pgs_backfilling, max_latency, max_delta_weight, bench_pool):

    # check if there is any work to do:
    update_osd_tree()
    total_weight = 0
    osd_list = []

    if osds:
        osd_list = osds
    elif host:
        osd_list = get_children(host)
        check_device_class(host, osd_list)

    # check total weight is greater than 0
    for osd in osd_list:
        total_weight += get_crush_weight(osd)
    if total_weight == 0:
        print "drain: no work to do, exiting"
        cleanup(bench_pool)
        sys.exit(0)

    # check num pgs backfilling
    npgs = get_num_backfilling()
    if npgs > max_pgs_backfilling:
        print "drain: npgs backfilling is too high, trying again later"
        return

    # check the latency
    latency = measure_latency(bench_pool)
    if latency > max_latency:
        print "drain: latency is too high, trying again later"
        return

    # there is some work to do
    print "drain: draining total weight %s" % total_weight

    if osds:
        # Reduce the weight of osds to 0 (unless exceeding max_delta_weight for the run)
        delta_weight = 0
        for osd in osd_list:
            if delta_weight > max_delta_weight:
                print "drain: reached max delta weight this round: %s" % delta_weight
                return

            weight = get_crush_weight(osd)
            if weight <= 0:
                print "drain: skipping %s with weight %s" % (osd, weight)
                continue

            new_weight = 0
            print "drain: %s new weight will be %s" % (osd, new_weight)
            crush_reweight(osd, new_weight)
            delta_weight += weight
        if delta_weight == 0:
            all_done(bench_pool)

    elif host:
        # Reduce the weight of the host by weight_reduction_factor (default 0.1)
        #   - unless higher than max_delta_weight*number_of_osds
        #       in this case, reduce by max_delta_weight*number_of_osds
        #   - or lower than 0.1*number_of_osds
        #       in this case, reduce by the weight of the subtree
        weight_reduction_factor = 0.1
        weight_reduction = weight_reduction_factor * total_weight
        if weight_reduction > max_delta_weight * len(osd_list):
            weight_reduction = max_delta_weight * len(osd_list)
        elif weight_reduction < 0.1 * len(osd_list):
            weight_reduction = total_weight

        new_weight = total_weight - weight_reduction
        if new_weight < 0:
            new_weight = 0

        per_osd_weight = new_weight / len(osd_list)
        print "drain: %s new weight will be %s (osd weight: %s)" % (host, new_weight, per_osd_weight)
        crush_reweight_subtree(host, per_osd_weight)
        if new_weight == 0:
            all_done(bench_pool)


def usage(code=0):
    print(
        """ceph-gentle-drain [OPTIONS]

        OPTIONS
        -o/--osds <osd>[,<osd>,...]    Comma separated OSDs to drain
        -s/--host <host>               Host to drain
        -l/--latency <N>               Max lantency ms, default 50
        -b/--backfills <N>             Max PGs backfilling, default 20
        -w/--weight <N>                Max decremental weight, default 2
        --bench-pool <POOL>            Pool used to measure latency, default 'test'

        Example:
        ceph-gentle-drain -o osd.0
        ceph-gentle-drain -s cephdata...
        """)
    sys.exit(code)


def main(argv):
    drain_osds = []
    drain_host = None
    max_latency = 50
    max_pgs_backfilling = 20
    max_delta_weight = 2
    bench_pool = "test"

    try:
        opts, args = getopt.getopt(
            argv,
            "ho:s:l:b:w:",
            ["osds=", "host=", "latency=", "backfills=", "weight=", "bench-pool="])
    except getopt.GetoptError:
        usage(2)

    for opt, arg in opts:
        if opt == '-h':
            usage()
        elif opt in ("-o", "--osds"):
            drain_osds = arg.split(',')
        elif opt in ("-s", "--host"):
            drain_host = arg
        elif opt in ("-l", "--latency"):
            max_latency = int(arg)
        elif opt in ("-b", "--backfills"):
            max_pgs_backfilling = int(arg)
        elif opt in ("-w", "--weight"):
            max_delta_weight = float(arg)
        elif opt in ("--bench-pool"):
            bench_pool = arg
        else:
            print("unknow option: %s" % opt)

    if not drain_osds and not drain_host:
        usage(2)

    print('==============================================================')
    if drain_osds:
      print('OSDs to drain: %s' % drain_osds)
    elif drain_host:
      print('Subtree to drain: %s' % drain_host)
    print('Max delta weight: %f' % max_delta_weight)
    print('Max latency (ms): %d' % max_latency)
    print('Max PGs backfilling: %d' % max_pgs_backfilling)
    print('Benchmark pool: %s' % bench_pool)
    print('==============================================================')

    prepare(bench_pool)

    while(True):
        drain(drain_osds, drain_host, max_pgs_backfilling, max_latency, max_delta_weight,
              bench_pool)
        print "main: sleeping 60s"
        time.sleep(60)

if __name__ == "__main__":
    main(sys.argv[1:])
